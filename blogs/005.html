<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>playing with sine waves using golang</title>
    <meta name="description" content="cause it is fun" />
    <meta
      name="keywords"
      content="programming, go, golang, audio programming, from scratch, computer science"
    />
    <meta name="author" content="0xmukesh" />

    <link rel="stylesheet" href="/styles.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  </head>
  <body class="blog">
    <h1>playing with sine waves using golang</h1>
    <p class="blog__byline">
      by <a href="/">mukesh</a> on
      <time datetime="2024-12-28">28th December 2024</time>
    </p>

    <p>
      while scrolling through youtube, i came across this video on my feed by
      <a href="https://www.youtube.com/@javidx9">javidx9</a> -
      <a href="https://youtu.be/tgamhuQnOkM?si=QnRopBay40F54sAH"
        >https://youtu.be/tgamhuQnOkM?si=QnRopBay40F54sAH</a
      >
      about building a sound synthesizer in c++, so i thought of giving audio
      programming a shot. in this blog post, we'll cover few of the basic topics
      and build a simple program which would generate a sine wave of a certain
      frequency and save it to a <code>.wave</code> file, amplify it and peform
      stereopanning on a given <code>.wave</code> file.
    </p>

    <h2>what is sound?</h2>

    <p>
      sound is a phenomenon caused by vibration in particles that propagates as
      a wave through a transmission medium such as air, water, or solids. most
      of the sounds in the real world propagate in the form of a sine wave (or
      combination of different sine waves).
    </p>

    <p>
      for example, the note A above middle C on the piano propagates as a
      (almost) pure sine wave with a frequency of 440Hz (<a
        href="https://www.reddit.com/r/AskPhysics/comments/10tffnh/how_can_a_piano_key_have_only_one_frequency/"
        >ref: how can a piano key only have one frequency?</a
      >) and it can be mathematically represented as follows:
    </p>

    <blockquote>y = sin(880&pi;x)</blockquote>

    <h2>what is audio?</h2>

    <p>
      sound is a mechanical wave energy, while audio is the electrical
      representation of that sound wave.
    </p>

    <p>
      a microphone converts the mechanical sound waves into analog signals which
      is later passed through an analog-digital converter (ADC) which converts
      these analog signals into digital signals, which would be understood by a
      computer.
    </p>

    <p>
      there are two important keywords in the context of digital audio -
      <b>bit rate</b> and <b>sample frequency</b>
    </p>

    <p>
      the analog signals hold information about various wave characteristics at
      that particular instant such as the amplitude. sample frequency is the
      number of times a
      <i>snapshot</i> of these characteristics is taken and these snapshots are
      later used to re-create the sound wave.
    </p>

    <p>
      most of the audio which is delivered nowadays either uses 44.1 kHz or 48
      kHz as the sample frequency. the frequency limit of humans range from 20
      Hz to 22 kHz. nyquist rate is the minimum sampling rate needed to
      accurately represent a signal and it is twice the highest frequency of the
      signal.
    </p>

    <blockquote>44100 = 2 * 22000 + 100</blockquote>

    <p>
      why isn't it 44 kHz? well, an additional 100 Hz sorta acts like a
      transition band or room for error, which prevents unwanted distortion in
      the higher frequencies.
    </p>

    <p>
      in the early days, digital audio was stored on modified video recorders
      and 44.1 kHz worked perfectly with the video equipment at that time and it
      became the industry standard.
    </p>

    <p>
      bit depth is related to the precision of each <i>snapshot</i>. if the bit
      depth is 16 then the maximum number which could be represented is +32767
      (((2^16 - 1) - 1)/2) and the least is -32767. a snapshot could either have
      +ve or -ve amplitude. so in simple words - the higher the bit depth, the
      more clearly it is represented digitally, at the regions with really high
      or really low frequencies.
    </p>

    <h2>crafting initial sounds</h2>

    <p>let's a simple program which would generate a sine wave of 440 Hz.</p>

    <pre><code class="language-go">package main

import (
  "encoding/binary"
  "fmt"
  "math"
  "os"
  "time"
)

const (
  duration   = 5
  sampleRate = 44100
  freq       = 440
)

func main() {
  ns := duration * sampleRate
  angle := (math.Pi * 2.0) / float64(ns)

  f, err := os.Create("wave.bin")
  if err != nil {
    panic(err.Error())
  }
  start := time.Now()

  for i := 0; i < ns; i++ {
    sample := math.Sin(angle * freq * float64(i))
    var buf [4]byte

    binary.LittleEndian.PutUint32(buf[:], math.Float32bits(float32(sample)))

    if _, err := f.Write(buf[:]); err != nil {
      panic(err.Error())
    }
  }

  fmt.Printf("done - %dms\n", time.Since(start).Milliseconds())
}</code></pre>

    <p>
      the above program generates a <code>.bin</code> file containing binary
      representation of the audio samples, at a sample rate of 44.1kHz.
    </p>

    <blockquote>y = sin(440x)</blockquote>

    <p>
      as sample rate is number of samples taken per second, number of samples
      can be found out with the help of duration and sample rate:
    </p>

    <blockquote>number of samples = (sample rate) * (duration)</blockquote>

    <p><code>angle</code> is the angular increment per sample.</p>

    <p>
      <code>sample</code> is snapshot of the wave characteristics at that
      moment, in this case it is the amplitude i.e. value of the function at
      that point.
    </p>

    <p>
      the sample (which is a floating point number) is converted to its
      corresponding little-endian byte representation and then written to
      <code>wave.bin</code>. i'm converting it to little-endian as my CPU (intel
      i5) uses little-endian. check which byte representation your machine's CPU
      follows via the following command:
    </p>

    <pre><code class="language-bash">lscpu | grep "Byte Order"</code></pre>

    <p>to play the audio, we can use <code>ffplay</code></p>

    <blockquote>ffplay -f f32le -ar 44100 -showmode 1 wave.bin</blockquote>

    <ol>
      <li>
        <code>-f</code> specifies the file format. <code>f32le</code> indicates
        that the audio is encoded in 32-bit litte-endian byte format.
      </li>

      <li>
        <code>-ar</code> specifies the audio sample rate, which is 44.1 kHz in
        this case.
      </li>

      <li>
        <code>-showmode 1</code> opens a GUI showing the sine wave re-created
        from the samples.
      </li>
    </ol>

    <p>
      on running the above <code>ffplay</code> command, you should hear a sound
      something similar to -
      <a href="https://files.catbox.moe/b8n1k9.mp4">rec.mp4</a>
    </p>

    <h2>adding exponential decay</h2>

    <p>
      right now, the audio abruptly ends. let's fix that by adding exponential
      decay. exponential decay keeps on gradually decreasing the amplitude,
      which leads to a neat <i>fade away</i> sorta effect.
    </p>

    <pre><code class="language-go">startAmplitude := 1.0
endAmplitude := 1.0e-4
decayFactor := math.Pow(endAmplitude/startAmplitude, 1.0/float64(ns))
// ...

for i := 0; i < ns; i++ {
  sample := math.Sin(angle * freq * float64(i))
  sample *= startAmplitude
  startAmplitude *= decayFactor

  var buf [4]byte

  binary.LittleEndian.PutUint32(buf[:], math.Float32bits(float32(sample)))

  if _, err := f.Write(buf[:]); err != nil {
    panic(err.Error())
  }
}
</code></pre>

    <p>
      on running the script, you should notice that the audio fades off that the
      end -
      <a href="https://files.catbox.moe/lcls0l.mp4">rec.mp4</a>
    </p>

    <h2>understanding wave file format</h2>

    <p>
      we have generated the byte code that can produce some sound, let's save it
      into a <code>wave</code> file, so it can be played by the media players
      rather than using <code>ffplay</code>.
    </p>

    <p>
      waveform audio file format or wave in short stores audio data as samples,
      along with some metadata such as number of audio channels (mono, stereo,
      etc.). a wave file is usually encoded using
      <a
        href="https://www.sciencedirect.com/topics/engineering/pulse-code-modulation"
        >pulse code modulation</a
      >
      (although, it isn't required to fully understand pulse code modulation to
      implement this blog post by yourself).
    </p>

    <p>
      a wave file follows a strict format and is majorly split into three
      <i>blocks</i> of data.
    </p>

    <ol>
      <li>header</li>
      <li>fmt - holds the related metadata</li>
      <li>raw data</li>
    </ol>

    <hr />

    <p>
      the structure of the header is as follows: (on the left side, byte offsets
      are mentioned and on the right side, the corresponding data's label)
    </p>

    <ol>
      <li>
        0 - 4 bytes - chunk id (must be equal to <code>RIFF</code>, written in
        little-endian. if it was written in big-endian, then it would be have
        been <code>RIFX</code>)
      </li>

      <li>4 - 8 bytes - chunk size</li>

      <li>8 - 12 bytes - format (must be equal to <code>WAVE</code>)</li>
    </ol>

    <hr />

    <p>the structure of the "fmt" block is as follows:</p>

    <ol>
      <li>12 - 16 - sub chunk 1 id (must be equal to <code>fmt </code>)</li>

      <li>16 - 20 - sub chunk 1 size</li>

      <li>
        20 - 22 - audio format (equal to <code>1</code>, if it is encoded via
        pulse code modulation)
      </li>

      <li>22 - 24 - number of audio channels (1 for mono, 2 for stereo)</li>

      <li>24 - 28 - sample rate (i.e. sample frequency)</li>

      <li>
        28 - 32 - byte rate (byte rate = (sample rate) * (number of audio
        channels) * (bits per sample) / 8)
      </li>

      <li>
        32 - 34 - block align (block align = (number of audio channels) * (bits
        per sample) / 8)
      </li>

      <li>34 - 36 - bits per sample (i.e. bit depth)</li>
    </ol>

    <hr />

    <p>the structure of the data block is as follows:</p>

    <ol>
      <li>36 - 40 - sub chunk 2 id (must be equal to <code>data</code>)</li>

      <li>40 - 44 - sub chunk 2 size</li>

      <li>44 - ... - raw samples</li>
    </ol>

    <hr />

    <p>
      here is a better pictorial representation of the structure -
      <a
        href="https://web.archive.org/web/20141213140451/https://ccrma.stanford.edu/courses/422/projects/WaveFormat/"
        >https://ccrma.stanford.edu/courses/422/projects/WaveFormat/</a
      >. if you wanna go a bit depth, then you play around by opening a
      <code>wave</code> file in hex editors like
      <a href="https://imhex.werwolv.net/">ImHex</a>.
    </p>

    <h2>working with wave files</h2>

    <p>
      let's first code out some structs adhering the above mentioned format.
    </p>

    <pre><code class="language-go">package types

type Sample float64

type WaveHeader struct {
  ChunkId   []byte
  ChunkSize int
}

type WaveFmt struct {
  SubChunk1Id   []byte 
  SubChunk1Size int    
  AudioFormat   int    
  NumOfChannels int    
  SampleRate    int    
  ByteRate      int    
  BlockAlign    int   
  BitsPerSample int
}</code></pre>

    <p>
      before coding out an implementation for <code>WaveWriter</code>, let's
      make a few utility functions which would convert ints/floats to their
      little-endian byte representations.
    </p>

    <pre><code class="language-go">func IntToBits(i int, size int) []byte {
  switch size {
  case 16:
    return Int16ToBits(i)
  case 32:
    return Int32ToBits(i)
  default:
    panic("invalid size. only 16 and 32 bits are accepted")
  }
}

func Int16ToBits(i int) []byte {
  b := make([]byte, 2)
  binary.LittleEndian.PutUint16(b, uint16(i))
  return b
}

func Int32ToBits(i int) []byte {
  b := make([]byte, 4)
  binary.LittleEndian.PutUint32(b, uint32(i))
  return b
}

func FloatToBits(f float64, size int) []byte {
  bits := math.Float64bits(f)
  b := make([]byte, 8)
  binary.LittleEndian.PutUint64(b, bits)

  switch size {
  case 2:
    return b[:2]
  case 4:
    return b[:4]
  }

  return b
}</code></pre>

    <p>
      and a few more utility functions which would convert
      <code>WaveHeader</code> and <code>WaveFmt</code> into their equivalent
      litte-endian byte representation.
    </p>

    <pre><code class="language-go">func WaveFmtToBits(wfmt types.WaveFmt) []byte {
  var b []byte

  b = append(b, wfmt.SubChunk1Id...)
  b = append(b, Int32ToBits(wfmt.SubChunk1Size)...)
  b = append(b, Int16ToBits(wfmt.AudioFormat)...)
  b = append(b, Int16ToBits(wfmt.NumOfChannels)...)
  b = append(b, Int32ToBits(wfmt.SampleRate)...)
  b = append(b, Int32ToBits(wfmt.ByteRate)...)
  b = append(b, Int16ToBits(wfmt.BlockAlign)...)
  b = append(b, Int16ToBits(wfmt.BitsPerSample)...)

  return b
}

func SamplesToBits(samples []types.Sample, wfmt types.WaveFmt) ([]byte, error) {
  var b []byte

  for _, s := range samples {
    var multiplier int

    switch wfmt.BitsPerSample {
    case 8:
      multiplier = math.MaxInt8
    case 16:
      multiplier = math.MaxInt16
    case 32:
      multiplier = math.MaxInt32
    case 64:
      multiplier = math.MaxInt64
    default:
      return nil, fmt.Errorf("invalid size - %d, must be 8, 16, 32 or 64-bits only", wfmt.BitsPerSample)
    }

    bits := IntToBits(int(float64(s)*float64(multiplier)), wfmt.BitsPerSample)
    b = append(b, bits...)
  }

  return b, nil
}

func CreateHeaderBits(samples []types.Sample, wfmt types.WaveFmt) []byte {
  var b []byte

  chunkSizeInBits := Int32ToBits(36 + (len(samples)*wfmt.NumOfChannels*wfmt.BitsPerSample)/8)

  b = append(b, []byte(constants.WaveChunkId)...)
  b = append(b, chunkSizeInBits...)
  b = append(b, []byte(constants.WaveFileFormat)...)

  return b
}</code></pre>

    <p>
      now as we have all the utility functions set up, let's write a simple
      struct
      <code>WaveWriter</code> which implements a method
      <code>WriteWaveFile</code> which would save the sample data into a wave
      file.
    </p>

    <pre><code class="language-go">type WaveWriter struct{}

func NewWaveWriter() WaveWriter {
  return WaveWriter{}
}

func (w WaveWriter) WriteWaveFile(file string, samples []types.Sample, metadata types.WaveFmt) error {
  f, err := os.Create(file)
  if err != nil {
    return err
  }
  defer f.Close()

  var data []byte

  headerBits := utils.CreateHeaderBits(samples, metadata)
  data = append(data, headerBits...)

  wfmtInBits := utils.WaveFmtToBits(metadata)
  data = append(data, wfmtInBits...)

  data = append(data, []byte(constants.WaveSubChunk2Id)...)
  data = append(data, utils.Int32ToBits(len(samples)*metadata.NumOfChannels*metadata.BitsPerSample/8)...)

  samplesBits, err := utils.SamplesToBits(samples, metadata)
  if err != nil {
    return err
  }
  data = append(data, samplesBits...)

  if _, err := f.Write(data); err != nil {
    return err
  }

  return nil
}</code></pre>

    <p>
      the header is created using the above utility function
      (<code>CreateHeaderBits</code>) and also the fmt block and samples are
      converted to their equivalent byte representations using the above utility
      functions (<code>WaveFmtToBits</code> and <code>SamplesToBits</code>).
    </p>

    <p>
      let's use the <code>WriteWaveFile</code> method in our script to save the
      samples into a <code>wave</code> file.
    </p>

    <pre><code class="language-go">var samples []types.Sample

for i := 0; i < ns; i++ {
  sample := types.Sample(math.Sin(angle*freq*float64(i)) * startAmplitude)
  startAmplitude *= decayFactor

  samples = append(samples, sample)
}

waveWriter := helpers.NewWaveWriter()
if err := waveWriter.WriteWaveFile("test.wav", samples, wavefmt); err != nil {
  panic(err.Error())
}</code></pre>

    <p>
      and on running the script, a new file named <code>test.wav</code> must be
      created, which must sound similar to -
      <a href="https://files.catbox.moe/bq0vik.wav">test.wav</a>
    </p>

    <h2>reading wave files</h2>

    <p>
      we've successfully implemented the first part of the blog post which is to
      generate a sine wave of a constant frequency and save it to a wave file.
      the next part is to amplify a given wave file. to amplify a given input
      wave file, we have to first parse through it. to do so, we have to
      implement
      <code>WaveReader</code>.
    </p>

    <p>
      before actually implementing <code>WaveReader</code>, we have add few
      utility functions which convert bits to ints/floats.
    </p>

    <pre><code class="language-go">func BitsToInt(b []byte, size int) int {
  switch size {
  case 16:
    return Bits16ToInt(b)
  case 32:
    return Bits32ToInt(b)
  default:
    panic("invalid size. only 16 and 32 bits are accepted")
  }
}

func Bits16ToInt(b []byte) int {
  if len(b) != 2 {
    panic(fmt.Errorf("invalid size. expected 2, got %d", len(b)))
  }

  var payload int16
  buf := bytes.NewReader(b)
  if err := binary.Read(buf, binary.LittleEndian, &payload); err != nil {
    panic(err.Error())
  }

  return int(payload)
}

func Bits32ToInt(b []byte) int {
  if len(b) != 4 {
    panic(fmt.Errorf("invalid size. expected 4, got %d", len(b)))
  }

  var payload int32
  buf := bytes.NewReader(b)
  if err := binary.Read(buf, binary.LittleEndian, &payload); err != nil {
    panic(err.Error())
  }

  return int(payload)
}

func BitsToFloat(b []byte) float64 {
  switch len(b) {
  case 4:
    bits32 := binary.LittleEndian.Uint32(b)
    return float64(math.Float32frombits(bits32))
  case 8:
    bits64 := binary.LittleEndian.Uint64(b)
    return math.Float64frombits(bits64)
  default:
    panic(fmt.Errorf("invalid size: %d, must be 32 or 64 bits", len(b)*8))
  }
}</code></pre>

    <p>
      the <code>WaveReader</code> struct implements a few methods which parses
      through the input <code>wave</code> file and returns parsed header
      (<code>WaveHeader</code>), fmt block (<code>WaveFmt</code>) and samples
      (<code>[]Samples</code>). while parsing, the samples are scaled down as
      during writing, the samples were multiplied with max value of that
      corresponding bit length so it must be divided while parsing to maintain
      consistency.
    </p>

    <pre><code class="language-go">type WaveReader struct{}

func NewWaveReader() WaveReader {
  return WaveReader{}
}

func (r WaveReader) ParseFile(file string) (types.Wave, error) {
  f, err := os.Open(file)
  if err != nil {
    return types.Wave{}, err
  }
  defer f.Close()

  data, err := io.ReadAll(f)
  if err != nil {
    return types.Wave{}, err
  }

  header, err := r.parseHeader(data)
  if err != nil {
    return types.Wave{}, err
  }

  wavefmt, err := r.parseMetadata(data)
  if err != nil {
    return types.Wave{}, err
  }

  samples, err := r.parseData(data)
  if err != nil {
    return types.Wave{}, err
  }

  wave := types.Wave{
    WaveHeader: header,
    WaveFmt:    wavefmt,
    Samples:    samples,
  }

  return wave, nil
}

func (r WaveReader) parseHeader(data []byte) (types.WaveHeader, error) {
  header := types.WaveHeader{}

  chunkId := data[0:4]
  if string(chunkId) != constants.WaveChunkId {
    return header, errors.New("invalid file")
  }
  header.ChunkId = chunkId

  chunkSize := data[4:8]
  header.ChunkSize = utils.Bits32ToInt(chunkSize)

  format := data[8:12]
  if string(format) != constants.WaveFileFormat {
    return header, errors.New("invalid format")
  }

  return header, nil
}

func (r WaveReader) parseMetadata(data []byte) (types.WaveFmt, error) {
  metadata := types.WaveFmt{}

  subChunk1Id := data[12:16]
  if string(subChunk1Id) != constants.WaveSubChunk1Id {
    return metadata, fmt.Errorf("invalid sub chunk 1 id - %s", string(subChunk1Id))
  }

  metadata.SubChunk1Id = subChunk1Id
  metadata.SubChunk1Size = utils.Bits32ToInt(data[16:20])
  metadata.AudioFormat = utils.Bits16ToInt(data[20:22])
  metadata.NumOfChannels = utils.Bits16ToInt(data[22:24])
  metadata.SampleRate = utils.Bits32ToInt(data[24:28])
  metadata.ByteRate = utils.Bits32ToInt(data[28:32])
  metadata.BlockAlign = utils.Bits16ToInt(data[32:34])
  metadata.BitsPerSample = utils.Bits16ToInt(data[34:36])

  return metadata, nil
}

func (r WaveReader) parseData(data []byte) ([]types.Sample, error) {
  metadata, err := r.parseMetadata(data)
  if err != nil {
    return nil, err
  }

  subChunk2Id := data[36:40]
  if string(subChunk2Id) != constants.WaveSubChunk2Id {
    return nil, fmt.Errorf("invalid sub chunk 2 id - %s", string(subChunk2Id))
  }

  bytesPerSampleSize := metadata.BitsPerSample / 8
  rawData := data[44:]

  samples := []types.Sample{}

  for i := 0; i < len(rawData); i += bytesPerSampleSize {
    rawSample := rawData[i : i+bytesPerSampleSize]
    unscaledSample := utils.BitsToInt(rawSample, metadata.BitsPerSample)
    scaledSample := types.Sample(float64(unscaledSample) / float64(utils.MaxValue(metadata.BitsPerSample)))
    samples = append(samples, scaledSample)
  }

  return samples, nil
}</code></pre>

    <p>
      if you have noticed, i have added a new type <code>Wave</code> which just
      contains wave header, fmt block and samples - easier to access and return
      the data through <code>Wave</code>.
    </p>

    <pre><code class="language-go">type Wave struct {
  WaveHeader
  WaveFmt
  Samples []Sample
}</code></pre>

    <h2>amplifying a given wave file</h2>

    <p>
      in simple words, amplification is nothing more than scaling up/down the
      amplitude of the wave at a given point. so basically, messing around with
      each individual sample.
    </p>

    <pre><code class="language-go">waveReader := helpers.NewWaveReader()
waveWriter := helpers.NewWaveWriter()

wave, err := waveReader.ParseFile(input)
if err != nil {
  return err
}

var updatedSamples []types.Sample

for _, sample := range wave.Samples {
  updatedSample := types.Sample(float64(sample) * scaleFactor)
  updatedSamples = append(updatedSamples, updatedSample)
}

if err := waveWriter.WriteWaveFile(output, updatedSamples, wave.WaveFmt); err != nil {
  return err
}</code></pre>

    <p>
      [out-of-context] i have re-structured the entire program into a CLI using
      <a href="https://cobra.dev">cobra</a>. generating the constant frequency
      sine wave is handled by <code>generate</code> command and amplification
      part is handled <code>amplify</code> command. it is not entire necessarily
      to use cobra, it was more of a personal choice.
    </p>

    <p>
      this is the output when a 440Hz pure sine wave is scaled down by 0.2 times
      -
      <a href="https://files.catbox.moe/5bdo6o.wav">output.wav</a>
    </p>

    <footer style="text-align: center; margin-top: 32px">
      <a href="/">0xmukesh</a>
    </footer>

    <script src="/js/blogs/add-top-nav.js"></script>
    <script>
      hljs.highlightAll();
    </script>
  </body>
</html>
